import streamlit as st
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from datetime import datetime
from wordcloud import WordCloud
import matplotlib.pyplot as plt
from openai import OpenAI

# --- ìƒìˆ˜ ì •ì˜ ---
EXPECTED_STUDENT_SHEET_HEADER = ["ë‚ ì§œ", "ê°ì •", "ê°ì‚¬í•œ ì¼", "í•˜ê³  ì‹¶ì€ ë§", "ì„ ìƒë‹˜ ìª½ì§€"]
EMOTION_GROUPS = ["ğŸ˜€ ê¸ì •", "ğŸ˜ ë³´í†µ", "ğŸ˜¢ ë¶€ì •"]
FONT_PATH = "NanumGothic.ttf"  # ì˜ˆ: "NanumGothic.ttf" (ì•±ê³¼ ê°™ì€ í´ë”ì— ìˆì„ ê²½ìš°)

GPT_CUMULATIVE_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì´ˆë“±í•™êµ í•™ìƒë“¤ì˜ ì‹¬ë¦¬ ë° ìƒë‹´ ë¶„ì•¼ì—ì„œ ê¹Šì€ ì „ë¬¸ì„±ì„ ê°€ì§„ AI ìƒë‹´ ë³´ì¡°ì…ë‹ˆë‹¤. 
ë‹¹ì‹ ì˜ ë¶„ì„ì€ ì¸ê°„ ì¤‘ì‹¬ ìƒë‹´ ì´ë¡ , ì¸ì§€ í–‰ë™ ì´ë¡  ë“± ì‹¤ì œ ìƒë‹´ ì´ë¡ ì— ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤. 
ì œê³µë˜ëŠ” í•œ í•™ìƒì˜ **ëˆ„ì ëœ ìµëª… ì¼ê¸° ê¸°ë¡ ì „ì²´ (ê°ì •, ê°ì‚¬í•œ ì¼, í•˜ê³  ì‹¶ì€ ë§)**ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ë‹¤ìŒ 6ê°€ì§€ í•­ëª©ì— ëŒ€í•´ êµ¬ì²´ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ë¦¬í¬íŠ¸ë¥¼ ì„ ìƒë‹˜ê»˜ ì œê³µí•´ì£¼ì„¸ìš”. 
í•™ìƒì˜ ì´ë¦„ì´ë‚˜ ê°œì¸ ì‹ë³„ ì •ë³´ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”. ë‹µë³€ì€ ëª…í™•í•œ í•­ëª© êµ¬ë¶„ì„ ìœ„í•´ ë§ˆí¬ë‹¤ìš´ í—¤ë”ë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”.

ì œê³µë  ëˆ„ì  ì¼ê¸° ë‚´ìš© í˜•ì‹ (ì‹¤ì œ ë‚´ìš©ì€ ì•„ë˜ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤):
- ì „ì²´ ê°ì • ê¸°ë¡: [ë‚ ì§œ1: ê°ì •1, ë‚ ì§œ2: ê°ì •2, ...]
- ì „ì²´ ê°ì‚¬í•œ ì¼ ê¸°ë¡: [ë‚ ì§œ1: ê°ì‚¬í•œ ì¼1, ë‚ ì§œ2: ê°ì‚¬í•œ ì¼2, ...]
- ì „ì²´ í•˜ê³  ì‹¶ì€ ë§ ê¸°ë¡: [ë‚ ì§œ1: í•˜ê³  ì‹¶ì€ ë§1, ë‚ ì§œ2: í•˜ê³  ì‹¶ì€ ë§2, ...]

í•™ìƒì˜ ëˆ„ì  ê¸°ë¡ ë°ì´í„°:
{cumulative_diary_data_for_gpt}

ë¦¬í¬íŠ¸ í•­ëª©:
1.  **ëˆ„ì ëœ ê°ì • ê¸°ë¡ ë¶„ì„ ë° ê°€ì¥ ë³´í¸ì ì¸ ê°ì • ìƒíƒœ**: ì œê³µëœ ëª¨ë“  'ê°ì •' ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì´ ê°€ì¥ ìì£¼ í‘œí˜„í•˜ëŠ” ê°ì •(ë“¤)ì€ ë¬´ì—‡ì¸ì§€, ê¸ì •/ë¶€ì •/ì¤‘ë¦½ ê°ì •ì˜ ì „ë°˜ì ì¸ ë¹„ìœ¨ì´ë‚˜ ê²½í–¥ì„±ì€ ì–´ë– í•œì§€, ê·¸ë¦¬ê³  ì´ë¥¼ í†µí•´ íŒŒì•…í•  ìˆ˜ ìˆëŠ” í•™ìƒì˜ ê°€ì¥ ë³´í¸ì ì¸ ê°ì • ìƒíƒœì— ëŒ€í•´ ë¶„ì„í•´ì£¼ì„¸ìš”.
2.  **ë¬¸ì²´ ë° í‘œí˜„ íŠ¹ì„± (ëˆ„ì  ê¸°ë¡ ê¸°ë°˜)**: ëˆ„ì ëœ ê¸€ ì „ì²´ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” í•™ìƒì˜ ì–¸ì–´ ìˆ˜ì¤€(ì´ˆë“±í•™ìƒ ìˆ˜ì¤€ ê³ ë ¤), ë¬¸ì¥ êµ¬ì¡°ì˜ ë³µì¡ì„±, ìê¸° ìƒê°ì´ë‚˜ ê°ì •ì„ ì–¼ë§ˆë‚˜ ëª…í™•í•˜ê³  í’ë¶€í•˜ê²Œ í‘œí˜„í•˜ê³  ìˆëŠ”ì§€, ì£¼ê´€ì  ê°ì • í‘œí˜„ì˜ ê°•ë„ëŠ” ì–´ë– í•œì§€ ë“±ì„ í‰ê°€í•´ì£¼ì„¸ìš”.
3.  **ì£¼ìš” í‚¤ì›Œë“œ ë° ì£¼ì œ ì¶”ì¶œ (ëˆ„ì  ê¸°ë¡ ê¸°ë°˜)**: ëˆ„ì ëœ ê¸€ ì „ì²´ì—ì„œ ë°˜ë³µì ìœ¼ë¡œ ë‚˜íƒ€ë‚˜ê±°ë‚˜ ì¤‘ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” í•µì‹¬ ë‹¨ì–´(í‚¤ì›Œë“œ)ë¥¼ 3-5ê°œ ì¶”ì¶œí•˜ê³ , ì´ë¥¼ í†µí•´ í•™ìƒì˜ ì£¼ìš” ê´€ì‹¬ì‚¬, ìì£¼ ì–¸ê¸‰ë˜ëŠ” ëŒ€ìƒ(ì˜ˆ: ì¹œêµ¬, ê°€ì¡±, íŠ¹ì • í™œë™ ë“±), ë˜ëŠ” ë°˜ë³µë˜ëŠ” ìƒí™©ì´ë‚˜ ì‚¬ê±´ì„ íŒŒì•…í•´ì£¼ì„¸ìš”.
4.  **ëˆ„ì ëœ ê¸°ë¡ì— ëŒ€í•œ ì¢…í•© ìš”ì•½**: ìœ„ ë¶„ì„ë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ëˆ„ì ëœ ê¸°ë¡ ì „ì²´ë¥¼ í†µí•´ íŒŒì•…í•  ìˆ˜ ìˆëŠ” í•™ìƒì˜ ìƒê°, ê²½í—˜, ê°ì •ì˜ í•µì‹¬ì ì¸ íŒ¨í„´ì´ë‚˜ ë‚´ìš©ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì£¼ì„¸ìš”.
5.  **ê´€ì°° ë° ë³€í™” ì¶”ì´ (ëˆ„ì  ê¸°ë¡ ê¸°ë°˜)**: ëˆ„ì ëœ ê¸°ë¡ì„ í†µí•´ í•™ìƒì˜ ê°ì •, ìƒê°, í‘œí˜„ ë°©ì‹ ë“±ì—ì„œ ì‹œê°„ì— ë”°ë¥¸ ë³€í™”ë‚˜ ì¼ê´€ëœ íŒ¨í„´ì´ ìˆë‹¤ë©´ ì–¸ê¸‰í•´ì£¼ì„¸ìš”. ì„ ìƒë‹˜ê»˜ì„œ ì•ìœ¼ë¡œ ì´ í•™ìƒì˜ ì–´ë–¤ ë©´ì„ ì¢€ ë” ê´€ì‹¬ ìˆê²Œ ì§€ì¼œë³´ë©´ ì¢‹ì„ì§€, ë˜ëŠ” ì–´ë–¤ ê¸ì •ì /ë¶€ì •ì  ë³€í™”ì˜ ê°€ëŠ¥ì„±ì´ ì—¿ë³´ì´ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
6.  **ì„ ìƒë‹˜ì„ ìœ„í•œ ìƒë‹´ì  ì¡°ì–¸ (ëˆ„ì  ê¸°ë¡ ê¸°ë°˜)**: ëˆ„ì ëœ ê¸°ë¡ì—ì„œ íŒŒì•…ëœ í•™ìƒì˜ íŠ¹ì„±ì„ ë°”íƒ•ìœ¼ë¡œ, ì„ ìƒë‹˜ê»˜ì„œ ì´ í•™ìƒì„ ì§€ì§€í•˜ê³  ë•ê¸° ìœ„í•´ í™œìš©í•  ìˆ˜ ìˆëŠ” ì¸ê°„ ì¤‘ì‹¬ì  ë˜ëŠ” ì¸ì§€ í–‰ë™ì  ì ‘ê·¼ ë°©ì‹ì— ê¸°ë°˜í•œ êµ¬ì²´ì ì¸ ìƒë‹´ ì „ëµì´ë‚˜ ì†Œí†µ ë°©ë²•ì„ 1-2ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.
"""

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="ê°ì • ì¼ê¸°ì¥ (êµì‚¬ìš©)", page_icon="ğŸ§‘â€ğŸ«", layout="wide")

# --- Helper Functions ---
@st.cache_resource
def authorize_gspread():
    try:
        google_creds_dict = st.secrets["GOOGLE_CREDENTIALS"]
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_dict(google_creds_dict, scope)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"Google API ì¸ì¦ ì¤‘ ì˜¤ë¥˜: {e}. '.streamlit/secrets.toml' ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop(); return None

@st.cache_data(ttl=600)
def get_students_df(_client_gspread):
    if not _client_gspread: return pd.DataFrame()
    try:
        ws = _client_gspread.open("í•™ìƒëª©ë¡").sheet1
        df = pd.DataFrame(ws.get_all_records())
        if not df.empty and ("ì´ë¦„" not in df.columns or "ì‹œíŠ¸URL" not in df.columns):
            st.error("'í•™ìƒëª©ë¡' ì‹œíŠ¸ì— 'ì´ë¦„'/'ì‹œíŠ¸URL' ì—´ì´ ì—†ìŠµë‹ˆë‹¤."); return pd.DataFrame()
        return df
    except Exception as e: st.error(f"í•™ìƒ ëª©ë¡ ë¡œë”© ì˜¤ë¥˜: {e}"); return pd.DataFrame()

def get_records_from_row2_header(worksheet, headers):
    all_values = worksheet.get_all_values()
    if len(all_values) < 2: return []
    data_rows, records = all_values[2:], []
    for r_vals in data_rows:
        rec, pad_len = {}, len(headers) - len(r_vals)
        padded_vals = r_vals + [None] * pad_len if pad_len > 0 else r_vals
        for i, h in enumerate(headers): rec[h] = padded_vals[i] if i < len(padded_vals) else None
        records.append(rec)
    return records

@st.cache_data(ttl=300)
def fetch_all_students_today_data(_students_df, today_str, _client_gspread, headers):
    all_data = []
    if _students_df.empty: return all_data
    prog_bar = st.progress(0, text="ìš”ì•½ ì •ë³´ ë¡œë”© ì¤‘... (0%)")
    total = len(_students_df)
    for i, (_, row) in enumerate(_students_df.iterrows()):
        name, url = row["ì´ë¦„"], row["ì‹œíŠ¸URL"]
        entry = {"name": name, "emotion_today": None, "message_today": None, "error": None}
        prog_val = (i + 1) / total
        prog_bar.progress(prog_val, text=f"'{name}' í™•ì¸ ì¤‘... ({int(prog_val*100)}%)")
        if not url or not isinstance(url, str) or not url.startswith("http"):
            entry["error"] = "ì‹œíŠ¸ URL í˜•ì‹ ì˜¤ë¥˜"; all_data.append(entry); continue
        try:
            ws = _client_gspread.open_by_url(url).sheet1
            recs = get_records_from_row2_header(ws, headers)
            found = False
            for r in recs:
                if r.get("ë‚ ì§œ") == today_str:
                    entry["emotion_today"], entry["message_today"] = r.get("ê°ì •"), r.get("í•˜ê³  ì‹¶ì€ ë§")
                    found = True; break
            if not found: entry["error"] = "ì˜¤ëŠ˜ ì¼ê¸° ì—†ìŒ"
        except Exception as e: entry["error"] = f"ì˜¤ë¥˜ ({type(e).__name__})"
        all_data.append(entry)
    prog_bar.empty(); return all_data

# --- OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
client_openai = None
openai_api_key = st.secrets.get("OPENAI_API_KEY")
if openai_api_key:
    try: client_openai = OpenAI(api_key=openai_api_key)
    except Exception as e: st.warning(f"OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e} (GPT ê¸°ëŠ¥ ë¹„í™œì„±í™”)")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
session_defaults = {
    "teacher_logged_in": False, "all_students_today_data_loaded": False,
    "all_students_today_data": [], "detail_view_selected_student": ""
}
for k, v in session_defaults.items():
    if k not in st.session_state: st.session_state[k] = v

# --- êµì‚¬ìš© ë¡œê·¸ì¸ ---
if not st.session_state.teacher_logged_in:
    st.title("ğŸ§‘â€ğŸ« ê°ì •ì¼ê¸° ë¡œê·¸ì¸ (êµì‚¬ìš©)")
    admin_pw = st.text_input("ê´€ë¦¬ì ë¹„ë°€ë²ˆí˜¸", type="password", key="admin_pw_final_consolidated")
    if st.button("ë¡œê·¸ì¸", key="admin_login_btn_final_consolidated"):
        if admin_pw == st.secrets.get("ADMIN_TEACHER_PASSWORD", "silverline"):
            st.session_state.teacher_logged_in = True
            for k, v_init in session_defaults.items(): # ë¡œê·¸ì¸ ì‹œ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ë¡œê·¸ì¸ ìƒíƒœ ì œì™¸)
                 if k != "teacher_logged_in": st.session_state[k] = v_init
            st.rerun()
        else: st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
else: # --- êµì‚¬ìš© ê¸°ëŠ¥ í˜ì´ì§€ ---
    g_client = authorize_gspread()
    students_main_df = get_students_df(g_client)

    st.sidebar.title("ğŸ§‘â€ğŸ« êµì‚¬ ë©”ë‰´")
    if st.sidebar.button("ë¡œê·¸ì•„ì›ƒ", key="logout_final_consolidated"):
        for k, v_init in session_defaults.items(): st.session_state[k] = v_init
        st.rerun()
    if st.sidebar.button("ì˜¤ëŠ˜ í•™ìƒ ë°ì´í„° ìƒˆë¡œê³ ì¹¨ â™»ï¸", key="refresh_data_final_consolidated"):
        st.session_state.all_students_today_data_loaded = False
        st.cache_data.clear(); st.rerun()

    st.title("ğŸ§‘â€ğŸ« êµì‚¬ìš© ëŒ€ì‹œë³´ë“œ")

    if not st.session_state.all_students_today_data_loaded:
        if students_main_df.empty:
            st.warning("'í•™ìƒëª©ë¡' ì‹œíŠ¸ê°€ ë¹„ì–´ìˆê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€. í™•ì¸ í›„ 'ìƒˆë¡œê³ ì¹¨' í•´ì£¼ì„¸ìš”.")
            st.session_state.all_students_today_data = []
            st.session_state.all_students_today_data_loaded = True # ë¡œë“œ ì‹œë„ ì™„ë£Œ
        else:
            today_str = datetime.today().strftime("%Y-%m-%d")
            st.session_state.all_students_today_data = fetch_all_students_today_data(
                students_main_df, today_str, g_client, EXPECTED_STUDENT_SHEET_HEADER)
            st.session_state.all_students_today_data_loaded = True
            if st.session_state.all_students_today_data: st.success("ì˜¤ëŠ˜ ì í•™ìƒ ìš”ì•½ ì •ë³´ ë¡œë“œ ì™„ë£Œ!")
            # ë¡œë“œ í›„ ìë™ìœ¼ë¡œ reruní•  í•„ìš” ì—†ìŒ, Streamlitì´ ìœ„ì ¯ ë³€ê²½ ì‹œ ë‹¤ì‹œ ê·¸ë¦¼

    summary_data = st.session_state.get("all_students_today_data", [])
    tabs_list = ["ì˜¤ëŠ˜ì˜ í•™ê¸‰ ê°ì • ë¶„í¬ ğŸ“Š", "í•™ìƒë“¤ì´ ì „ë‹¬í•˜ëŠ” ë©”ì‹œì§€ ğŸ’Œ", "í•™ìƒë³„ ì¼ê¸° ìƒì„¸ ë³´ê¸° ğŸ“–"]
    tab1, tab2, tab3 = st.tabs(tabs_list)

    with tab1: # ì˜¤ëŠ˜ì˜ í•™ê¸‰ ê°ì • ë¶„í¬
        st.header(tabs_list[0])
        st.markdown(f"**ì¡°íšŒ ë‚ ì§œ:** {datetime.today().strftime('%Y-%m-%d')}")
        if not summary_data: st.info("ìš”ì•½í•  í•™ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            cats = {g: [] for g in EMOTION_GROUPS}
            cats.update({"ê°ì • ë¯¸ë¶„ë¥˜": [], "ì¼ê¸° ë¯¸ì œì¶œ ë˜ëŠ” ì˜¤ë¥˜": []})
            for d in summary_data:
                name = d["name"]
                if d["error"] and d["error"] != "ì˜¤ëŠ˜ ì¼ê¸° ì—†ìŒ": cats["ì¼ê¸° ë¯¸ì œì¶œ ë˜ëŠ” ì˜¤ë¥˜"].append(f"{name} ({d['error']})")
                elif d["error"] == "ì˜¤ëŠ˜ ì¼ê¸° ì—†ìŒ" or not d["emotion_today"]: cats["ì¼ê¸° ë¯¸ì œì¶œ ë˜ëŠ” ì˜¤ë¥˜"].append(name)
                elif d["emotion_today"] and isinstance(d["emotion_today"], str) and " - " in d["emotion_today"]:
                    main_emo = d["emotion_today"].split(" - ")[0].strip()
                    if main_emo in EMOTION_GROUPS: cats[main_emo].append(name)
                    else: cats["ê°ì • ë¯¸ë¶„ë¥˜"].append(f"{name} (ê°ì •: {d['emotion_today']})")
                else: cats["ì¼ê¸° ë¯¸ì œì¶œ ë˜ëŠ” ì˜¤ë¥˜"].append(f"{name} (ê°ì • í˜•ì‹ ì˜¤ë¥˜: {d['emotion_today']})")
            
            cols_t1 = st.columns(len(EMOTION_GROUPS))
            for i, grp in enumerate(EMOTION_GROUPS):
                with cols_t1[i]:
                    st.subheader(f"{grp} ({len(cats[grp])}ëª…)")
                    if cats[grp]: st.markdown("\n".join([f"- {n}" for n in sorted(cats[grp])]))
                    else: st.info("ì´ ê°ì •ì„ ëŠë‚€ í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            col_exp1, col_exp2 = st.columns(2)
            with col_exp1:
                if cats["ì¼ê¸° ë¯¸ì œì¶œ ë˜ëŠ” ì˜¤ë¥˜"]:
                    with st.expander(f"ğŸ“ ì¼ê¸° ë¯¸ì œì¶œ/ì˜¤ë¥˜ ({len(cats['ì¼ê¸° ë¯¸ì œì¶œ ë˜ëŠ” ì˜¤ë¥˜'])}ëª…)"):
                        st.markdown("\n".join([f"- {s}" for s in sorted(cats["ì¼ê¸° ë¯¸ì œì¶œ ë˜ëŠ” ì˜¤ë¥˜"])]))
            with col_exp2:
                if cats["ê°ì • ë¯¸ë¶„ë¥˜"]:
                    with st.expander(f"ğŸ¤” ê°ì • ë¯¸ë¶„ë¥˜ ({len(cats['ê°ì • ë¯¸ë¶„ë¥˜'])}ëª…)"):
                        st.markdown("\n".join([f"- {s}" for s in sorted(cats["ê°ì • ë¯¸ë¶„ë¥˜"])]))
    
    with tab2: # í•™ìƒë“¤ì´ ì „ë‹¬í•˜ëŠ” ë©”ì‹œì§€
        st.header(tabs_list[1])
        if not summary_data: st.info("ìš”ì•½í•  í•™ìƒ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            neg_msg, other_msg = [], []
            for d in summary_data:
                if d["error"] or not d["emotion_today"] or not d["message_today"] or not d["message_today"].strip(): continue
                emo_full = d["emotion_today"]
                if not isinstance(emo_full, str) or " - " not in emo_full: continue
                item = {"name": d["name"], "emotion": emo_full, "message": d["message_today"].strip()}
                if emo_full.split(" - ")[0].strip() == "ğŸ˜¢ ë¶€ì •": neg_msg.append(item)
                elif emo_full.split(" - ")[0].strip() in ["ğŸ˜€ ê¸ì •", "ğŸ˜ ë³´í†µ"]: other_msg.append(item)
            
            if not neg_msg and not other_msg: st.success("ì˜¤ëŠ˜ ì„ ìƒë‹˜ì´ë‚˜ ì¹œêµ¬ë“¤ì—ê²Œ í•˜ê³  ì‹¶ì€ ë§ì„ ì ì€ í•™ìƒì´ ì—†ìŠµë‹ˆë‹¤. ğŸ˜Š")
            else:
                st.subheader("ğŸ˜¥ ë¶€ì •ì  ê°ì • í•™ìƒë“¤ì˜ ë©”ì‹œì§€")
                if neg_msg:
                    for item in sorted(neg_msg, key=lambda x: x['name']):
                        with st.container(border=True): st.markdown(f"**í•™ìƒëª…:** {item['name']} (<span style='color:red;'>{item['emotion']}</span>)\n\n**ë©”ì‹œì§€:**\n> {item['message']}", unsafe_allow_html=True)
                else: st.info("ì˜¤ëŠ˜, ë¶€ì •ì ì¸ ê°ì •ê³¼ í•¨ê»˜ ë©”ì‹œì§€ë¥¼ ë‚¨ê¸´ í•™ìƒì€ ì—†ìŠµë‹ˆë‹¤.")
                st.markdown("---")
                st.subheader("ğŸ˜Š ê·¸ ì™¸ ê°ì • í•™ìƒë“¤ì˜ ë©”ì‹œì§€")
                if other_msg:
                    for item in sorted(other_msg, key=lambda x: x['name']):
                        with st.container(border=True): st.markdown(f"**í•™ìƒëª…:** {item['name']} ({item['emotion']})\n\n**ë©”ì‹œì§€:**\n> {item['message']}")
                else: st.info("ì˜¤ëŠ˜, ê¸ì •ì  ë˜ëŠ” ë³´í†µ ê°ì •ê³¼ í•¨ê»˜ ë©”ì‹œì§€ë¥¼ ë‚¨ê¸´ í•™ìƒì€ ì—†ìŠµë‹ˆë‹¤.")

    with tab3: # í•™ìƒë³„ ì¼ê¸° ìƒì„¸ ë³´ê¸°
        st.header(tabs_list[2])
        if students_main_df.empty: st.warning("í•™ìƒ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
        else:
            opts_students = [""] + students_main_df["ì´ë¦„"].tolist()
            sel_idx = opts_students.index(st.session_state.detail_view_selected_student) if st.session_state.detail_view_selected_student in opts_students else 0
            st.session_state.detail_view_selected_student = st.selectbox("í•™ìƒ ì„ íƒ", options=opts_students, index=sel_idx, key="sel_student_tab3_final")
            
            selected_student = st.session_state.detail_view_selected_student
            if selected_student:
                s_info = students_main_df[students_main_df["ì´ë¦„"] == selected_student].iloc[0]
                s_name, s_url = s_info["ì´ë¦„"], s_info["ì‹œíŠ¸URL"]
                
                b_col1, d_col2 = st.columns([1,3])
                with b_col1:
                    if st.button(f"ë‹¤ë¥¸ í•™ìƒ ì„ íƒ", key=f"back_btn_tab3_{s_name}"):
                        st.session_state.detail_view_selected_student = ""; st.rerun()
                with d_col2:
                    sel_date = st.date_input("ë‚ ì§œ ì„ íƒ", value=datetime.today(), key=f"date_pick_tab3_{s_name}")
                sel_date_str = sel_date.strftime("%Y-%m-%d")

                if not s_url or not isinstance(s_url, str) or not s_url.startswith("http"):
                    st.error(f"'{s_name}' í•™ìƒì˜ ì‹œíŠ¸ URLì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    try:
                        df_s_all_entries = pd.DataFrame()
                        ws_s_detail = None # ì›Œí¬ì‹œíŠ¸ ê°ì²´ëŠ” í•„ìš”í•  ë•Œë§Œ ì‚¬ìš©

                        # í•™ìƒ ì „ì²´ ê¸°ë¡ ë¡œë“œ (ìºì‹± ì•ˆí•¨ - ìƒì„¸ë³´ê¸°ì—ì„  í•­ìƒ ìµœì‹  ë°ì´í„°)
                        with st.spinner(f"'{s_name}' í•™ìƒì˜ ì „ì²´ ì¼ê¸° ê¸°ë¡ ë¡œë”© ì¤‘..."):
                            ws_s_detail = g_client.open_by_url(s_url).sheet1
                            all_s_entries = get_records_from_row2_header(ws_s_detail, EXPECTED_STUDENT_SHEET_HEADER)
                            df_s_all_entries = pd.DataFrame(all_s_entries)

                        if df_s_all_entries.empty or "ë‚ ì§œ" not in df_s_all_entries.columns:
                            st.warning(f"'{s_name}' í•™ìƒ ì‹œíŠ¸ì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜ 'ë‚ ì§œ' ì—´ì´ ì—†ìŠµë‹ˆë‹¤.")
                        else:
                            entry_df = df_s_all_entries[df_s_all_entries["ë‚ ì§œ"] == sel_date_str]
                            if not entry_df.empty: # ì„ íƒí•œ ë‚ ì§œì— ì¼ê¸°ê°€ ìˆëŠ” ê²½ìš°
                                diary_e = entry_df.iloc[0]
                                st.subheader(f"ğŸ“˜ {s_name} ({sel_date_str}) ì¼ê¸°"); st.divider()
                                st.write(f"**ê°ì •:** {diary_e.get('ê°ì •', 'N/A')}")
                                st.write(f"**ê°ì‚¬í•œ ì¼:** {diary_e.get('ê°ì‚¬í•œ ì¼', 'N/A')}")
                                st.write(f"**í•˜ê³  ì‹¶ì€ ë§:** {diary_e.get('í•˜ê³  ì‹¶ì€ ë§', 'N/A')}")
                                note_val = diary_e.get('ì„ ìƒë‹˜ ìª½ì§€', '')
                                st.write(f"**ì„ ìƒë‹˜ ìª½ì§€:** {note_val}")

                                note_in = st.text_area(f"âœï¸ ìª½ì§€ ì‘ì„±/ìˆ˜ì •", value=note_val, key=f"note_in_{s_name}_{sel_date_str}")
                                if st.button(f"ğŸ’¾ ìª½ì§€ ì €ì¥", key=f"save_note_btn_{s_name}_{sel_date_str}"):
                                    if not note_in.strip() and not note_val: st.warning("ìª½ì§€ ë¹„ì–´ìˆìŒ.")
                                    else:
                                        try:
                                            r_idx, hdrs = -1, ws_s_detail.row_values(2)
                                            for i, r in enumerate(all_s_entries):
                                                if r.get("ë‚ ì§œ") == sel_date_str: r_idx = i + 3; break
                                            if r_idx != -1:
                                                note_c_idx = hdrs.index("ì„ ìƒë‹˜ ìª½ì§€") + 1 if "ì„ ìƒë‹˜ ìª½ì§€" in hdrs else 5
                                                ws_s_detail.update_cell(r_idx, note_c_idx, note_in)
                                                st.success(f"ìª½ì§€ ì €ì¥!"); st.cache_data.clear(); st.rerun() # ìƒì„¸ ë°ì´í„°ëŠ” ìºì‹œ ì•ˆí•˜ë¯€ë¡œ st.rerun()ë§Œìœ¼ë¡œë„ ê°±ì‹ ë  ê²ƒ
                                            else: st.error("ìª½ì§€ ì €ì¥ ëŒ€ìƒ ì¼ê¸° ì—†ìŒ.")
                                        except Exception as e: st.error(f"ìª½ì§€ ì €ì¥ ì˜¤ë¥˜: {e}")
                            else: 
                                st.info(f"'{s_name}' í•™ìƒì€ {sel_date_str}ì— ì‘ì„±í•œ ì¼ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤.")

                        # í•™ìƒ ì „ì²´ ê¸°ë¡ ê¸°ë°˜ ë¶„ì„ (ëˆ„ì  & GPT) - í•™ìƒ ê¸°ë¡ì´ ìˆì„ ë•Œë§Œ ë²„íŠ¼ í‘œì‹œ
                        if not df_s_all_entries.empty:
                            st.markdown("---"); st.subheader("ğŸ“Š í•™ìƒ ì „ì²´ ê¸°ë¡ ê¸°ë°˜ ë¶„ì„")
                            
                            # ëˆ„ì  ë¶„ì„ (ì›Œë“œí´ë¼ìš°ë“œ, ê°ì •í†µê³„) ë²„íŠ¼
                            if st.button(f"{s_name} í•™ìƒ ì „ì²´ ê¸°ë¡ ëˆ„ì  ë¶„ì„ (ì›Œë“œí´ë¼ìš°ë“œ ë“±)", key=f"cumul_analysis_btn_{s_name}"):
                                st.write("##### í•™ìƒ ì „ì²´ ê°ì • ëŒ€ë¶„ë¥˜ í†µê³„")
                                if "ê°ì •" in df_s_all_entries.columns and not df_s_all_entries["ê°ì •"].empty:
                                    df_s_all_entries['ê°ì • ëŒ€ë¶„ë¥˜'] = df_s_all_entries['ê°ì •'].astype(str).apply(
                                        lambda x: x.split(" - ")[0].strip() if isinstance(x, str) and " - " in x else "ë¯¸ë¶„ë¥˜")
                                    st.bar_chart(df_s_all_entries['ê°ì • ëŒ€ë¶„ë¥˜'].value_counts())
                                else: st.info("ê°ì • ë°ì´í„° ë¶€ì¡±.")
                                
                                st.write("##### í•™ìƒ ì „ì²´ 'ê°ì‚¬í•œ ì¼' & 'í•˜ê³  ì‹¶ì€ ë§' ë‹¨ì–´ ë¶„ì„")
                                wc_txts = []
                                for col in ["ê°ì‚¬í•œ ì¼", "í•˜ê³  ì‹¶ì€ ë§"]:
                                    if col in df_s_all_entries.columns: wc_txts.extend(df_s_all_entries[col].dropna().astype(str).tolist())
                                wc_data = " ".join(wc_txts)
                                if wc_data.strip():
                                    try:
                                        wc_img = WordCloud(font_path=FONT_PATH, width=700, height_ratio=0.5, background_color="white").generate(wc_data)
                                        fig, ax = plt.subplots(); ax.imshow(wc_img, interpolation='bilinear'); ax.axis("off"); st.pyplot(fig)
                                    except Exception as e: st.error(f"ì›Œë“œí´ë¼ìš°ë“œ ì˜¤ë¥˜ (í°íŠ¸: '{FONT_PATH}'): {e}")
                                else: st.info("ì›Œë“œí´ë¼ìš°ë“œìš© ë‹¨ì–´ ë¶€ì¡±.")
                            
                            # GPT ëˆ„ì  ë¶„ì„ ë²„íŠ¼
                            if st.button(f"{s_name} í•™ìƒ ì „ì²´ ê¸°ë¡ GPT ì‹¬ì¸µ ë¶„ì„ ğŸ“", key=f"gpt_cumulative_btn_{s_name}"):
                                if not openai_api_key or not client_openai:
                                    st.error("OpenAI API í‚¤ ë˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ë¯¸ì„¤ì •.")
                                else:
                                    with st.spinner("GPTê°€ í•™ìƒì˜ ì „ì²´ ëˆ„ì  ê¸°ë¡ì„ ì‹¬ì¸µ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (ì‹œê°„ ì†Œìš”)"):
                                        try:
                                            # ëˆ„ì  ë°ì´í„° ì¤€ë¹„ (ê°ì •, ê°ì‚¬í•œ ì¼, í•˜ê³  ì‹¶ì€ ë§)
                                            cumulative_emotions = [f"{r.get('ë‚ ì§œ','')}: {r.get('ê°ì •','')}" for r in all_s_entries if r.get('ê°ì •')]
                                            cumulative_gratitude = [f"{r.get('ë‚ ì§œ','')}: {r.get('ê°ì‚¬í•œ ì¼','')}" for r in all_s_entries if r.get('ê°ì‚¬í•œ ì¼','').strip()]
                                            cumulative_message = [f"{r.get('ë‚ ì§œ','')}: {r.get('í•˜ê³  ì‹¶ì€ ë§','')}" for r in all_s_entries if r.get('í•˜ê³  ì‹¶ì€ ë§','').strip()]
                                            
                                            # ë„ˆë¬´ ê¸´ ë°ì´í„°ëŠ” ìš”ì•½ ë˜ëŠ” ì¼ë¶€ë§Œ ì „ë‹¬ ê³ ë ¤ (ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ë‹¤ í•©ì³ë´„)
                                            # ì‹¤ì œë¡œëŠ” í† í° ìˆ˜ ì œí•œ ê³ ë ¤ í•„ìš”
                                            data_for_gpt = (
                                                f"ì „ì²´ ê°ì • ê¸°ë¡:\n" + "\n".join(cumulative_emotions) + "\n\n"
                                                f"ì „ì²´ ê°ì‚¬í•œ ì¼ ê¸°ë¡:\n" + "\n".join(cumulative_gratitude) + "\n\n"
                                                f"ì „ì²´ í•˜ê³  ì‹¶ì€ ë§ ê¸°ë¡:\n" + "\n".join(cumulative_message)
                                            )
                                            # í† í° ìˆ˜ ì ˆì•½ì„ ìœ„í•´ ê° í•­ëª©ë³„ ìš”ì•½ ì „ë‹¬ë„ ê°€ëŠ¥
                                            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ í•©ì³ì„œ ì „ë‹¬
                                            
                                            # í”„ë¡¬í”„íŠ¸ í¬ë§·íŒ… (ë°ì´í„° ë¶€ë¶„ë§Œ ì±„ì›€)
                                            user_prompt_content = GPT_CUMULATIVE_SYSTEM_PROMPT.format(
                                                cumulative_diary_data_for_gpt=data_for_gpt
                                            )
                                            
                                            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì™€ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ìµœì‹  ë°©ì‹ì— ë” ë¶€í•©
                                            # GPT_CUMULATIVE_SYSTEM_PROMPTì˜ ì²« ë¶€ë¶„ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¡œ ì‚¬ìš©
                                            prompt_parts = GPT_CUMULATIVE_SYSTEM_PROMPT.split("ì œê³µëœ ëˆ„ì  ì¼ê¸° ë‚´ìš© í˜•ì‹ (ì‹¤ì œ ë‚´ìš©ì€ ì•„ë˜ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤):")
                                            system_instructions = prompt_parts[0].strip()
                                            user_request_template = "ì œê³µëœ ëˆ„ì  ì¼ê¸° ë‚´ìš© í˜•ì‹ (ì‹¤ì œ ë‚´ìš©ì€ ì•„ë˜ ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤):" + prompt_parts[1]
                                            
                                            formatted_user_request = user_request_template.format(
                                                 cumulative_diary_data_for_gpt=data_for_gpt
                                            )

                                            gpt_resp = client_openai.chat.completions.create(
                                                model="gpt-4o",
                                                messages=[
                                                    {"role": "system", "content": system_instructions},
                                                    {"role": "user", "content": formatted_user_request}
                                                ],
                                                temperature=0.7, max_tokens=3000 # ì¶©ë¶„í•œ ê¸¸ì´ í™•ë³´
                                            )
                                            gpt_analysis = gpt_resp.choices[0].message.content
                                            st.markdown("##### ğŸ’¡ GPT ëˆ„ì  ê¸°ë¡ ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸:")
                                            with st.expander("ë¶„ì„ ê²°ê³¼ ë³´ê¸°", expanded=True): st.markdown(gpt_analysis)
                                        except Exception as e: st.error(f"GPT ëˆ„ì  ë¶„ì„ ì˜¤ë¥˜: {e}")
                    except Exception as e: st.error(f"'{s_name}' í•™ìƒ ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            else: st.info("ìƒë‹¨ì—ì„œ í•™ìƒì„ ì„ íƒí•˜ì—¬ ìƒì„¸ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
